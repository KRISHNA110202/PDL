{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b098422",
   "metadata": {},
   "source": [
    "## SHREE KRISHNA KANTH S\n",
    "## 225229136\n",
    "## II MSc DATA SCIENCE \"A\"\n",
    "## PDL LAB 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87635b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784a400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries and open dataset\n",
    "# Assuming you have already loaded your dataset into a variable called 'data'\n",
    "data_full = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "data = pd.DataFrame()\n",
    "data['text'] = data_full.data\n",
    "data['source'] = data_full.target\n",
    "label=[]\n",
    "for i in data['source']:\n",
    "    label.append(data_full.target_names[i])\n",
    "data['label']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d55546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  source  \\\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10   \n",
       "1      My brother is in the market for a high-perform...       3   \n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17   \n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3   \n",
       "4      1)    I have an old Jasmine drive which I cann...       4   \n",
       "...                                                  ...     ...   \n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13   \n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12   \n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3   \n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1   \n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7   \n",
       "\n",
       "                          label  \n",
       "0              rec.sport.hockey  \n",
       "1      comp.sys.ibm.pc.hardware  \n",
       "2         talk.politics.mideast  \n",
       "3      comp.sys.ibm.pc.hardware  \n",
       "4         comp.sys.mac.hardware  \n",
       "...                         ...  \n",
       "18841                   sci.med  \n",
       "18842           sci.electronics  \n",
       "18843  comp.sys.ibm.pc.hardware  \n",
       "18844             comp.graphics  \n",
       "18845                 rec.autos  \n",
       "\n",
       "[18846 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34e7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_2080\\430632324.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['text'] = data['text'].str.replace('[^a-zA-Z\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Pre-processing the Text\n",
    "data['text'] = data['text'].str.lower()\n",
    "data['text'] = data['text'].str.replace('[^a-zA-Z\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48567281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Dataset Preparation\n",
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d136e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: LSTM Model Creation\n",
    "max_words = 10000  # You can adjust this based on your dataset\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_sequence_length = 100  # You can adjust this based on your dataset\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Modify this section to convert labels to integer labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert integer labels to one-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train_encoded)\n",
    "y_test_encoded = to_categorical(y_test_encoded)\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length))\n",
    "model_lstm.add(LSTM(100))\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Adjust the number of units based on your labels\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3c84be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "207/207 [==============================] - 18s 80ms/step - loss: 2.7692 - accuracy: 0.1259\n",
      "Epoch 2/20\n",
      "207/207 [==============================] - 17s 81ms/step - loss: 2.0167 - accuracy: 0.3025\n",
      "Epoch 3/20\n",
      "207/207 [==============================] - 17s 82ms/step - loss: 1.4677 - accuracy: 0.4910\n",
      "Epoch 4/20\n",
      "207/207 [==============================] - 17s 83ms/step - loss: 1.0933 - accuracy: 0.6359\n",
      "Epoch 5/20\n",
      "207/207 [==============================] - 17s 83ms/step - loss: 0.8084 - accuracy: 0.7379\n",
      "Epoch 6/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 0.6238 - accuracy: 0.8044\n",
      "Epoch 7/20\n",
      "207/207 [==============================] - 17s 83ms/step - loss: 0.4715 - accuracy: 0.8576\n",
      "Epoch 8/20\n",
      "207/207 [==============================] - 17s 83ms/step - loss: 0.4291 - accuracy: 0.8709\n",
      "Epoch 9/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 0.3367 - accuracy: 0.8999\n",
      "Epoch 10/20\n",
      "207/207 [==============================] - 18s 86ms/step - loss: 0.2587 - accuracy: 0.9274\n",
      "Epoch 11/20\n",
      "207/207 [==============================] - 18s 86ms/step - loss: 0.2344 - accuracy: 0.9332\n",
      "Epoch 12/20\n",
      "207/207 [==============================] - 18s 87ms/step - loss: 0.2243 - accuracy: 0.9345\n",
      "Epoch 13/20\n",
      "207/207 [==============================] - 18s 87ms/step - loss: 0.1928 - accuracy: 0.9434\n",
      "Epoch 14/20\n",
      "207/207 [==============================] - 19s 90ms/step - loss: 0.1781 - accuracy: 0.9488\n",
      "Epoch 15/20\n",
      "207/207 [==============================] - 18s 86ms/step - loss: 0.1644 - accuracy: 0.9529\n",
      "Epoch 16/20\n",
      "207/207 [==============================] - 18s 86ms/step - loss: 0.1829 - accuracy: 0.9478\n",
      "Epoch 17/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 0.1517 - accuracy: 0.9562\n",
      "Epoch 18/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 0.1252 - accuracy: 0.9642\n",
      "Epoch 19/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 0.1345 - accuracy: 0.9613\n",
      "Epoch 20/20\n",
      "207/207 [==============================] - 18s 85ms/step - loss: 0.1316 - accuracy: 0.9608\n",
      "177/177 [==============================] - 3s 12ms/step - loss: 3.2259 - accuracy: 0.5486\n",
      "LSTM Model - Loss: 3.2259039878845215, Accuracy: 0.548638105392456\n"
     ]
    }
   ],
   "source": [
    "model_lstm.fit(X_train_pad, y_train_encoded, epochs=20, batch_size=64)\n",
    "loss, accuracy = model_lstm.evaluate(X_test_pad, y_test_encoded)\n",
    "print(f\"LSTM Model - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99400898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "207/207 [==============================] - 10s 38ms/step - loss: 2.6375 - accuracy: 0.1302\n",
      "Epoch 2/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 1.8366 - accuracy: 0.3477\n",
      "Epoch 3/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 1.2378 - accuracy: 0.5776\n",
      "Epoch 4/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.8982 - accuracy: 0.7018\n",
      "Epoch 5/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.6837 - accuracy: 0.7799\n",
      "Epoch 6/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.5367 - accuracy: 0.8307\n",
      "Epoch 7/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.4245 - accuracy: 0.8692\n",
      "Epoch 8/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.3390 - accuracy: 0.8983\n",
      "Epoch 9/20\n",
      "207/207 [==============================] - 8s 39ms/step - loss: 0.2704 - accuracy: 0.9206\n",
      "Epoch 10/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.2377 - accuracy: 0.9324\n",
      "Epoch 11/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.2270 - accuracy: 0.9337\n",
      "Epoch 12/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.2096 - accuracy: 0.9391\n",
      "Epoch 13/20\n",
      "207/207 [==============================] - 8s 39ms/step - loss: 0.1900 - accuracy: 0.9449\n",
      "Epoch 14/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.1672 - accuracy: 0.9517\n",
      "Epoch 15/20\n",
      "207/207 [==============================] - 8s 38ms/step - loss: 0.1632 - accuracy: 0.9525\n",
      "Epoch 16/20\n",
      "207/207 [==============================] - 9s 42ms/step - loss: 0.1558 - accuracy: 0.9555\n",
      "Epoch 17/20\n",
      "207/207 [==============================] - 9s 43ms/step - loss: 0.1421 - accuracy: 0.9586\n",
      "Epoch 18/20\n",
      "207/207 [==============================] - 8s 40ms/step - loss: 0.1377 - accuracy: 0.9586\n",
      "Epoch 19/20\n",
      "207/207 [==============================] - 8s 40ms/step - loss: 0.1415 - accuracy: 0.9588\n",
      "Epoch 20/20\n",
      "207/207 [==============================] - 9s 41ms/step - loss: 0.1421 - accuracy: 0.9576\n",
      "177/177 [==============================] - 2s 6ms/step - loss: 3.3933 - accuracy: 0.5564\n",
      "CNN-LSTM Model - Loss: 3.3932783603668213, Accuracy: 0.5564202070236206\n"
     ]
    }
   ],
   "source": [
    "# Step 5: CNN-LSTM Model Creation\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length))\n",
    "model_cnn_lstm.add(Conv1D(128, 5, activation='relu'))\n",
    "model_cnn_lstm.add(MaxPooling1D(5))\n",
    "model_cnn_lstm.add(LSTM(100))\n",
    "model_cnn_lstm.add(Dense(64, activation='relu'))\n",
    "model_cnn_lstm.add(Dense(len(y.unique()), activation='softmax'))\n",
    "model_cnn_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_cnn_lstm.fit(X_train_pad, y_train_encoded, epochs=20, batch_size=64)\n",
    "loss, accuracy = model_cnn_lstm.evaluate(X_test_pad, y_test_encoded)\n",
    "print(f\"CNN-LSTM Model - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c890748a",
   "metadata": {},
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b4beca7",
   "metadata": {},
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bec87fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_2080\\168645916.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in embedding_matrix:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "207/207 [==============================] - 8s 27ms/step - loss: 2.9944 - accuracy: 0.0479\n",
      "Epoch 2/20\n",
      "207/207 [==============================] - 5s 26ms/step - loss: 2.9922 - accuracy: 0.0544\n",
      "Epoch 3/20\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 2.9912 - accuracy: 0.0538\n",
      "Epoch 4/20\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 2.9907 - accuracy: 0.0531\n",
      "Epoch 5/20\n",
      "207/207 [==============================] - 6s 29ms/step - loss: 2.9904 - accuracy: 0.0544\n",
      "Epoch 6/20\n",
      "207/207 [==============================] - 6s 29ms/step - loss: 2.9902 - accuracy: 0.0544\n",
      "Epoch 7/20\n",
      "207/207 [==============================] - 7s 32ms/step - loss: 2.9902 - accuracy: 0.0531\n",
      "Epoch 8/20\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 9/20\n",
      "207/207 [==============================] - 6s 31ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 10/20\n",
      "207/207 [==============================] - 7s 32ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 11/20\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 12/20\n",
      "207/207 [==============================] - 6s 31ms/step - loss: 2.9901 - accuracy: 0.0528\n",
      "Epoch 13/20\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 2.9901 - accuracy: 0.0531\n",
      "Epoch 14/20\n",
      "207/207 [==============================] - 6s 31ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 15/20\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 16/20\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 2.9901 - accuracy: 0.0527\n",
      "Epoch 17/20\n",
      "207/207 [==============================] - 6s 31ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 18/20\n",
      "207/207 [==============================] - 7s 32ms/step - loss: 2.9901 - accuracy: 0.0526\n",
      "Epoch 19/20\n",
      "207/207 [==============================] - 6s 29ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "Epoch 20/20\n",
      "207/207 [==============================] - 6s 29ms/step - loss: 2.9901 - accuracy: 0.0544\n",
      "177/177 [==============================] - 2s 8ms/step - loss: 2.9916 - accuracy: 0.0493\n",
      "Pre-trained Model - Loss: 2.9916112422943115, Accuracy: 0.04934559762477875\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Pre-trained Model Creation\n",
    "# Download and load pre-trained GloVe embeddings\n",
    "embedding_file = 'C:\\\\Users\\\\shree\\\\Downloads\\\\archive (5)\\\\glove.6B.100d.txt'\n",
    "\n",
    "embedding_matrix = {}\n",
    "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_matrix[word] = coefs\n",
    "\n",
    "embedding_dim = 100  # Should match the dimension of the GloVe embeddings\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(max_words, len(word_index) + 1)\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_matrix[i]\n",
    "    if word in embedding_matrix:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "model_pretrained = Sequential()\n",
    "model_pretrained.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length,\n",
    "                              weights=[embedding_matrix], trainable=False))\n",
    "model_pretrained.add(Conv1D(128, 5, activation='relu'))\n",
    "model_pretrained.add(MaxPooling1D(5))\n",
    "model_pretrained.add(LSTM(100))\n",
    "model_pretrained.add(Dense(64, activation='relu'))\n",
    "model_pretrained.add(Dense(len(y.unique()), activation='softmax'))\n",
    "model_pretrained.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_pretrained.fit(X_train_pad, y_train_encoded, epochs=20, batch_size=64)\n",
    "loss, accuracy = model_pretrained.evaluate(X_test_pad, y_test_encoded)\n",
    "print(f\"Pre-trained Model - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c079355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Improvements\n",
    "# You can try different dropout rates and test different splits for further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ca22f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "207/207 [==============================] - 20s 88ms/step - loss: 2.7216 - accuracy: 0.1110\n",
      "Epoch 2/20\n",
      "207/207 [==============================] - 18s 87ms/step - loss: 2.0979 - accuracy: 0.2774\n",
      "Epoch 3/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 1.5782 - accuracy: 0.4430\n",
      "Epoch 4/20\n",
      "207/207 [==============================] - 17s 84ms/step - loss: 1.2038 - accuracy: 0.5922\n",
      "Epoch 5/20\n",
      "207/207 [==============================] - 17s 82ms/step - loss: 0.9362 - accuracy: 0.6872\n",
      "Epoch 6/20\n",
      "207/207 [==============================] - 17s 82ms/step - loss: 0.7635 - accuracy: 0.7510\n",
      "Epoch 7/20\n",
      "207/207 [==============================] - 17s 82ms/step - loss: 0.6440 - accuracy: 0.7899\n",
      "Epoch 8/20\n",
      "207/207 [==============================] - 16s 79ms/step - loss: 0.5189 - accuracy: 0.8361\n",
      "Epoch 9/20\n",
      "207/207 [==============================] - 16s 79ms/step - loss: 0.4354 - accuracy: 0.8681\n",
      "Epoch 10/20\n",
      "207/207 [==============================] - 16s 78ms/step - loss: 0.3372 - accuracy: 0.9014\n",
      "Epoch 11/20\n",
      "207/207 [==============================] - 16s 78ms/step - loss: 0.2937 - accuracy: 0.9153\n",
      "Epoch 12/20\n",
      "207/207 [==============================] - 16s 77ms/step - loss: 0.2655 - accuracy: 0.9215\n",
      "Epoch 13/20\n",
      "207/207 [==============================] - 16s 78ms/step - loss: 0.2870 - accuracy: 0.9190\n",
      "Epoch 14/20\n",
      "207/207 [==============================] - 16s 79ms/step - loss: 0.2140 - accuracy: 0.9378\n",
      "Epoch 15/20\n",
      "207/207 [==============================] - 17s 80ms/step - loss: 0.2217 - accuracy: 0.9354\n",
      "Epoch 16/20\n",
      "207/207 [==============================] - 16s 78ms/step - loss: 0.1868 - accuracy: 0.9461\n",
      "Epoch 17/20\n",
      "207/207 [==============================] - 16s 80ms/step - loss: 0.1745 - accuracy: 0.9494\n",
      "Epoch 18/20\n",
      "207/207 [==============================] - 17s 80ms/step - loss: 0.2342 - accuracy: 0.9303\n",
      "Epoch 19/20\n",
      "207/207 [==============================] - 17s 81ms/step - loss: 0.1540 - accuracy: 0.9563\n",
      "Epoch 20/20\n",
      "207/207 [==============================] - 17s 81ms/step - loss: 0.1501 - accuracy: 0.9570\n",
      "177/177 [==============================] - 3s 12ms/step - loss: 2.9034 - accuracy: 0.5637\n",
      "LSTM Model with Dropout - Loss: 2.9033939838409424, Accuracy: 0.5636717081069946\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Improvements\n",
    "\n",
    "# 7.1 Dropout in LSTM Model\n",
    "model_lstm_with_dropout = Sequential()\n",
    "model_lstm_with_dropout.add(Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length))\n",
    "model_lstm_with_dropout.add(LSTM(100))\n",
    "model_lstm_with_dropout.add(Dropout(0.2))  # Add dropout layer with 20% dropout rate\n",
    "model_lstm_with_dropout.add(Dense(64, activation='relu'))\n",
    "model_lstm_with_dropout.add(Dense(len(y.unique()), activation='softmax'))\n",
    "model_lstm_with_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_lstm_with_dropout.fit(X_train_pad, y_train_encoded, epochs=20, batch_size=64)\n",
    "loss, accuracy = model_lstm_with_dropout.evaluate(X_test_pad, y_test_encoded)\n",
    "print(f\"LSTM Model with Dropout - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4c4d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "236/236 [==============================] - 12s 41ms/step - loss: 2.6023 - accuracy: 0.1510\n",
      "Epoch 2/20\n",
      "236/236 [==============================] - 9s 40ms/step - loss: 1.7138 - accuracy: 0.4026\n",
      "Epoch 3/20\n",
      "236/236 [==============================] - 9s 39ms/step - loss: 1.1753 - accuracy: 0.6066\n",
      "Epoch 4/20\n",
      "236/236 [==============================] - 9s 39ms/step - loss: 0.8304 - accuracy: 0.7345\n",
      "Epoch 5/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.6310 - accuracy: 0.8012\n",
      "Epoch 6/20\n",
      "236/236 [==============================] - 10s 40ms/step - loss: 0.5010 - accuracy: 0.8460\n",
      "Epoch 7/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.3924 - accuracy: 0.8793\n",
      "Epoch 8/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.3135 - accuracy: 0.9089\n",
      "Epoch 9/20\n",
      "236/236 [==============================] - 11s 47ms/step - loss: 0.2681 - accuracy: 0.9197\n",
      "Epoch 10/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.2280 - accuracy: 0.9331\n",
      "Epoch 11/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1987 - accuracy: 0.9426\n",
      "Epoch 12/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1813 - accuracy: 0.9475\n",
      "Epoch 13/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1736 - accuracy: 0.9491\n",
      "Epoch 14/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1662 - accuracy: 0.9512\n",
      "Epoch 15/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1598 - accuracy: 0.9524\n",
      "Epoch 16/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1502 - accuracy: 0.9549\n",
      "Epoch 17/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1472 - accuracy: 0.9562\n",
      "Epoch 18/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1452 - accuracy: 0.9565\n",
      "Epoch 19/20\n",
      "236/236 [==============================] - 10s 43ms/step - loss: 0.1449 - accuracy: 0.9568\n",
      "Epoch 20/20\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.1353 - accuracy: 0.9604\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 3.4000 - accuracy: 0.5549\n",
      "CNN-LSTM Model with Different Split - Loss: 3.400027275085449, Accuracy: 0.5549071431159973\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Different Data Split\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Re-tokenize and re-pad based on the new split\n",
    "tokenizer.fit_on_texts(X_train_new)\n",
    "X_train_seq_new = tokenizer.texts_to_sequences(X_train_new)\n",
    "X_test_seq_new = tokenizer.texts_to_sequences(X_test_new)\n",
    "X_train_pad_new = pad_sequences(X_train_seq_new, maxlen=max_sequence_length)\n",
    "X_test_pad_new = pad_sequences(X_test_seq_new, maxlen=max_sequence_length)\n",
    "\n",
    "# Encode the labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded_new = label_encoder.fit_transform(y_train_new)\n",
    "y_test_encoded_new = label_encoder.transform(y_test_new)\n",
    "\n",
    "# Convert integer labels to one-hot encoding\n",
    "y_train_encoded_new = to_categorical(y_train_encoded_new)\n",
    "y_test_encoded_new = to_categorical(y_test_encoded_new)\n",
    "\n",
    "model_cnn_lstm_split = Sequential()\n",
    "model_cnn_lstm_split.add(Embedding(input_dim=max_words, output_dim=100, input_length=max_sequence_length))\n",
    "model_cnn_lstm_split.add(Conv1D(128, 5, activation='relu'))\n",
    "model_cnn_lstm_split.add(MaxPooling1D(5))\n",
    "model_cnn_lstm_split.add(LSTM(100))\n",
    "model_cnn_lstm_split.add(Dense(64, activation='relu'))\n",
    "model_cnn_lstm_split.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Adjust the number of units based on your labels\n",
    "model_cnn_lstm_split.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_cnn_lstm_split.fit(X_train_pad_new, y_train_encoded_new, epochs=20, batch_size=64)\n",
    "loss, accuracy = model_cnn_lstm_split.evaluate(X_test_pad_new, y_test_encoded_new)\n",
    "print(f\"CNN-LSTM Model with Different Split - Loss: {loss}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2853d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n",
      "Predicted class: [8]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Predictions\n",
    "sample_text = \"Australia claimed the crucial wicket of Sri Lankan opener Pathum Nissanka...\"\n",
    "sample_text = sample_text.lower().replace('[^a-zA-Z\\s]', '')\n",
    "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
    "sample_sequence = pad_sequences(sample_sequence, maxlen=max_sequence_length)\n",
    "predicted_class = np.argmax(model_pretrained.predict(sample_sequence), axis=-1)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991ffc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
